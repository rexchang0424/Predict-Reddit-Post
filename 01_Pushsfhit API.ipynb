{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push Shift API data Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "\n",
    "Ｍy objective is to determine which channel to direct the player to, by the used of their words. I will be looking at two specific game, League of Legends and Rainbow 6. Because these two games have to most active community and the play style of the two games are very different. I will obtain subreddit API from both game and apply the data to two classifier regression models: Logistic Regression and Random Forest Classifier. Then I will observe top ten less/most likely words that player will mentioned in these two games.\n",
    "    \n",
    "#### Contents:\n",
    "- [Getting Submissions & Comments from Tom Clancy's Rainbow Six Siege Subreddit](#Getting-Submissions-and-Comments-from-Tom-Clancy's-Rainbow-Six-Siege-Subreddit)\n",
    "- [Getting Submissions and Comments from League of Legends Subreddit](#Getting-Submissions-and-Comments-from-League-of-Legends-Subreddit)\n",
    "- [Finalizing DataSet](#Finalizing-DataSet)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push-Shift API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am acquiring subreddit through API. I performed a loop that will continues to obtain data based on the prior date of previous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pushshift(reqtype, sub, after):\n",
    "    reqtype = reqtype\n",
    "    sub = sub\n",
    "    after = after\n",
    "    before = None\n",
    "    url = 'https://api.pushshift.io/reddit/search/'+reqtype+'?sort=desc&size=1000&after='+after+'&subreddit='+sub\n",
    "    print ('getting '+reqtype+' from '+sub)\n",
    "    res = requests.get(url)\n",
    "    data = json.loads(res.content)\n",
    "    if len(data['data']) > 0:\n",
    "        date = data['data'][-1]['created_utc']\n",
    "    else:\n",
    "        date = None\n",
    "    for i in range(9):\n",
    "        before = str(date)\n",
    "        url_i = 'https://api.pushshift.io/reddit/search/'+reqtype+'?sort=desc&size=1000&before='+before+'&after='+after+'&subreddit='+sub\n",
    "        print('getting url:'+ url_i)\n",
    "        res_i = requests.get(url_i)\n",
    "        data_i = json.loads(res_i.content)\n",
    "        data['data'].extend(data_i['data'])\n",
    "        date = data_i['data'][-1]['created_utc']\n",
    "        time.sleep(1)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Submissions and Comments from Tom Clancy's Rainbow Six Siege Subreddit\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission**<br/>\n",
    "In this case, I found out that I only needed the information in **_title_** and **_selftext_**  ; therefore, I combined those two variables into one column and named it **submission_text**.\n",
    "\n",
    "**Comment**<br/>\n",
    "I only needed the information lie within  **_body_** from my comments API.\n",
    "\n",
    "**Why?**<br/>\n",
    "- After obtained API from submission and comment, I filtered out the information that is required, then I concatenate two columns from two separate DataFrame into one DataFrame.\n",
    "- I set an new columns as my target (binary result), if the context is from rainbow six it will be 1, else 0.\n",
    "- I performed a Regular Expression (regex) to filtered out the context that contained any URLs. Because they obtained a big amount of unnecessary information and removing them can dramatically speed up processing.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting submission from rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1545069697&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544948080&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544821602&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544680702&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544564418&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544458972&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544332593&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544214529&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544107694&after=60d&subreddit=rainbow6\n"
     ]
    }
   ],
   "source": [
    "sub_r6 = pushshift('submission', 'rainbow6', '60d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting comment from rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545169999&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545159106&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545148482&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545138163&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545119818&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545102447&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545089351&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545080110&after=60d&subreddit=rainbow6\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545071887&after=60d&subreddit=rainbow6\n"
     ]
    }
   ],
   "source": [
    "com_r6 = pushshift('comment', 'rainbow6', '60d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub_r6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(com_r6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_r6 = pd.DataFrame(sub_r6)\n",
    "com_r6 = pd.DataFrame(com_r6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'author_cakeday', 'author_flair_background_color',\n",
       "       'author_flair_css_class', 'author_flair_richtext',\n",
       "       'author_flair_template_id', 'author_flair_text',\n",
       "       'author_flair_text_color', 'author_flair_type', 'author_fullname',\n",
       "       'author_patreon_flair', 'can_mod_post', 'contest_mode', 'created_utc',\n",
       "       'crosspost_parent', 'crosspost_parent_list', 'domain', 'edited',\n",
       "       'full_link', 'gildings', 'id', 'is_crosspostable', 'is_meta',\n",
       "       'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable',\n",
       "       'is_self', 'is_video', 'link_flair_background_color',\n",
       "       'link_flair_css_class', 'link_flair_richtext', 'link_flair_template_id',\n",
       "       'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked',\n",
       "       'media', 'media_embed', 'media_only', 'no_follow', 'num_comments',\n",
       "       'num_crossposts', 'over_18', 'parent_whitelist_status', 'permalink',\n",
       "       'pinned', 'post_hint', 'preview', 'pwls', 'retrieved_on', 'score',\n",
       "       'secure_media', 'secure_media_embed', 'selftext', 'send_replies',\n",
       "       'spoiler', 'stickied', 'subreddit', 'subreddit_id',\n",
       "       'subreddit_subscribers', 'subreddit_type', 'thumbnail',\n",
       "       'thumbnail_height', 'thumbnail_width', 'title', 'url',\n",
       "       'whitelist_status', 'wls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_r6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'author_cakeday', 'author_flair_background_color',\n",
       "       'author_flair_css_class', 'author_flair_richtext',\n",
       "       'author_flair_template_id', 'author_flair_text',\n",
       "       'author_flair_text_color', 'author_flair_type', 'author_fullname',\n",
       "       'author_patreon_flair', 'body', 'created_utc', 'distinguished',\n",
       "       'gildings', 'id', 'link_id', 'no_follow', 'parent_id', 'permalink',\n",
       "       'retrieved_on', 'score', 'send_replies', 'stickied', 'subreddit',\n",
       "       'subreddit_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_r6.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_r6['submission_text'] = sub_r6['title'] + sub_r6['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow6 = pd.concat([sub_r6[['submission_text']], com_r6[['body']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow6['context'] = rainbow6['body'] + rainbow6['submission_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow6['context'] = [re.sub('http[s]?:\\/\\/[^\\s]*','',text) for text in rainbow6.context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow6.drop(['body','submission_text'], axis=1, inplace=True)\n",
    "rainbow6['rainbow6']= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>rainbow6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imagine having an elite skin when you're banne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I legit haven’t been able to open a pack all s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's a community challenge right nowNoice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The toxicity carries over to reddit lolThe abs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JeBaited. Feels Bad ManSiege Servers Recently....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  rainbow6\n",
       "0  Imagine having an elite skin when you're banne...         1\n",
       "1  I legit haven’t been able to open a pack all s...         1\n",
       "2          It's a community challenge right nowNoice         1\n",
       "3  The toxicity carries over to reddit lolThe abs...         1\n",
       "4  JeBaited. Feels Bad ManSiege Servers Recently....         1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainbow6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Submissions and Comments from League of Legends Subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be doing to same steps for League of Legends. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission**<br/>\n",
    "In this case, I found out that I only needed the information in **_title_** and **_selftext_**  ; therefore, I combined those two variables into one column and named it **submission_text**.\n",
    "\n",
    "**Comment**<br/>\n",
    "I only needed the information lie within  **_body_** from my comments API.\n",
    "\n",
    "**Why?**<br/>\n",
    "- After obtained API from submission and comment, I filtered out the information that is required, then I concatenate two columns from two separate DataFrame into one DataFrame.\n",
    "- I set an new columns as my target (binary result), if the context is from rainbow six it will be 1, else 0.\n",
    "- I performed a Regular Expression (regex) to filtered out the context that contained any URLs. Because they obtained a big amount of unnecessary information and removing them can dramatically speed up processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting submission from leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1545067473&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544953677&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544827008&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544724847&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544615115&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544512178&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544404230&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544309665&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/submission?sort=desc&size=1000&before=1544229732&after=60d&subreddit=leagueoflegends\n"
     ]
    }
   ],
   "source": [
    "data_lol = pushshift('submission', 'leagueoflegends', '60d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting comment from leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545175287&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545168479&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545162463&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545155985&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545150091&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545143886&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545137019&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545128517&after=60d&subreddit=leagueoflegends\n",
      "getting url:https://api.pushshift.io/reddit/search/comment?sort=desc&size=1000&before=1545119778&after=60d&subreddit=leagueoflegends\n"
     ]
    }
   ],
   "source": [
    "data_lolc = pushshift('comment', 'leagueoflegends', '60d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lolc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set my result to a DataFrame\n",
    "sub_lol = pd.DataFrame(data_lol)\n",
    "com_lol = pd.DataFrame(data_lolc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_lol.to_csv('./datas/sub_lol.csv')\n",
    "com_lol.to_csv('./datas/com_lol.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_lol['submission_text'] = sub_lol['title'] + sub_lol['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = pd.concat([sub_lol[['submission_text']], com_lol[['body']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_text</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is Obi Zex Kenobi? 78% Winrate in high Cha...</td>\n",
       "      <td>Yup! It was amazing how quickly they released ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My friend tryied to troll me but he changed wh...</td>\n",
       "      <td>First of all, you are getting better. Because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SIMPLE QUESTION: Your dream opponent is...?How...</td>\n",
       "      <td>I'm pretty new to reddit so idrk what you mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Interview] The Former SKT T1 Support, Wolf, T...</td>\n",
       "      <td>Maybe its seems like there is no progress but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to do deal with the disappointment/shame o...</td>\n",
       "      <td>Kalista, just because it explains Hecarims, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     submission_text  \\\n",
       "0  Who is Obi Zex Kenobi? 78% Winrate in high Cha...   \n",
       "1  My friend tryied to troll me but he changed wh...   \n",
       "2  SIMPLE QUESTION: Your dream opponent is...?How...   \n",
       "3  [Interview] The Former SKT T1 Support, Wolf, T...   \n",
       "4  How to do deal with the disappointment/shame o...   \n",
       "\n",
       "                                                body  \n",
       "0  Yup! It was amazing how quickly they released ...  \n",
       "1  First of all, you are getting better. Because ...  \n",
       "2  I'm pretty new to reddit so idrk what you mean...  \n",
       "3  Maybe its seems like there is no progress but ...  \n",
       "4  Kalista, just because it explains Hecarims, th...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol['context'] = lol['body'] + lol['submission_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol['context'] = [re.sub('http[s]?:\\/\\/[^\\s]*', '',str(text)) for text in lol.context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol.drop(['body','submission_text'], axis=1, inplace=True)\n",
    "lol['rainbow6'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalizing DataSet\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened?**<br/>\n",
    "I concatenated the two dataframe from each subreddit **rainbow6** and **leagueoflegends** into our finalized dataframe `df` then safe to `.csv` file. I also used regex to remove the text that are related to the subreddit itself to change the purity of our data to better reflected the context for the target community instead of just a block of words. and ready to move forward to the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([lol,rainbow6], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context'] = df.context.map(lambda x: re.sub('(rainbow6|leagueoflegends)[s]?',' ',x, flags= re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context'] = df.context.map(lambda x: re.sub('[0-9]', ' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>rainbow6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yup! It was amazing how quickly they released ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First of all, you are getting better. Because ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm pretty new to reddit so idrk what you mean...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maybe its seems like there is no progress but ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalista, just because it explains Hecarims, th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  rainbow6\n",
       "0  Yup! It was amazing how quickly they released ...         0\n",
       "1  First of all, you are getting better. Because ...         0\n",
       "2  I'm pretty new to reddit so idrk what you mean...         0\n",
       "3  Maybe its seems like there is no progress but ...         0\n",
       "4  Kalista, just because it explains Hecarims, th...         0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./datas/df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
